{
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "",
  "signature": "sha256:1edb3193824bd752207e4cb794f30b664f703e783b852d6ee1be901c0a1719d8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using regularized logistic regression to classify email"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import scipy.io\n",
      "import utils\n",
      "import numpy as np\n",
      "from sklearn import linear_model\n",
      "\n",
      "# No modifications in this script\n",
      "# complete the functions in util.py; then run the script\n",
      "\n",
      "# load the spam data in\n",
      "\n",
      "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
      "\n",
      "# Preprocess the data \n",
      "\n",
      "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
      "Xtrain_logt = utils.log_features(Xtrain)\n",
      "Xtrain_bin = utils.bin_features(Xtrain)\n",
      "\n",
      "Xtest_std = (Xtest - mu)/sigma\n",
      "Xtest_logt = utils.log_features(Xtest)\n",
      "Xtest_bin = utils.bin_features(Xtest)\n",
      "\n",
      "# find good lambda by cross validation for these three sets\n",
      "\n",
      "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
      "\n",
      "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
      "    print \"best_lambda = \", best_lambda\n",
      "\n",
      "    # train a classifier on best_lambda and run it\n",
      "    if penalty == \"l2\":\n",
      "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
      "    else:\n",
      "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
      "    lreg.fit(X,ytrain)\n",
      "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
      "    predy = lreg.predict(Xt)\n",
      "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
      "\n",
      "print \"L2 Penalty experiments -----------\"\n",
      "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
      "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
      "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
      "\n",
      "print \"L1 Penalty experiments -----------\"\n",
      "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
      "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
      "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "L2 Penalty experiments -----------\n",
        "best_lambda =  0.1\n",
        "Coefficients = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [-4.86311365] [[-2.74146465e-02 -2.25297587e-01  1.21840939e-01  2.29362871e+00\n",
        "   2.70425714e-01  2.32851166e-01  9.28595395e-01  2.95200240e-01\n",
        "   1.62205937e-01  6.78260499e-02 -8.32604448e-02 -1.60373355e-01\n",
        "  -4.72247648e-02  1.07677126e-02  1.87903316e-01  8.19771814e-01\n",
        "   5.09528967e-01  3.98711572e-02  2.67729698e-01  3.47047593e-01\n",
        "   2.60498921e-01  3.64605162e-01  7.25019549e-01  1.96728252e-01\n",
        "  -3.15395700e+00 -4.03133782e-01 -1.25451045e+01 -6.16581444e-02\n",
        "  -1.56114612e+00 -5.51429695e-02 -3.00815079e-02  4.07263514e-01\n",
        "  -3.68156438e-01 -1.43611773e+00 -5.87180437e-01  4.44294920e-01\n",
        "   4.23159426e-02 -1.56897094e-01 -4.55330855e-01 -1.02250297e-01\n",
        "  -3.54273292e+00 -1.72944493e+00 -4.37529278e-01 -1.05999941e+00\n",
        "  -9.18599336e-01 -1.75490332e+00 -1.67475861e-01 -9.56875213e-01\n",
        "  -3.65653117e-01 -1.36535501e-01 -6.58692473e-02  2.06714025e-01\n",
        "   1.70694382e+00  1.21460316e+00 -3.35269831e-01  1.56141393e+00\n",
        "   3.68775721e-01]]\n",
        "Accuracy on set aside test set for  std  =  0.9296875\n",
        "best_lambda =  0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "utils.py:32: RuntimeWarning: divide by zero encountered in log\n",
        "  logf += 1.0 + np.log(X)\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-16fd560db4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"L2 Penalty experiments -----------\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mrun_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtest_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mrun_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_logt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtest_logt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"logt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mrun_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_bin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtest_bin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"bin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-1-16fd560db4ef>\u001b[0m in \u001b[0;36mrun_dataset\u001b[0;34m(X, ytrain, Xt, ytest, type, penalty)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mlreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbest_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mlreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Coefficients = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpredy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/peter/.local/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1216\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/peter/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
        "\u001b[0;32m/home/peter/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/peter/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}