{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  5.1\n",
      "Coefficients =  [-1.5157442] [[-0.01840684 -0.21266707  0.13182708  0.44223938  0.26062597  0.18525779\n",
      "   0.89365549  0.3144773   0.14226525  0.06250421 -0.04832104 -0.15022897\n",
      "  -0.05030445  0.02958276  0.23882469  0.75866615  0.46075246  0.08858727\n",
      "   0.25983544  0.21891496  0.26201495  0.40558311  0.74337909  0.26638332\n",
      "  -1.68322246 -0.61771416 -1.60710912 -0.11831285 -0.62573686 -0.17975929\n",
      "  -0.28377359 -0.20404886 -0.41382315 -0.38475413 -0.32583552  0.30817705\n",
      "   0.00445086 -0.14093724 -0.37210461 -0.0946275  -0.57102237 -0.89163658\n",
      "  -0.31089036 -0.67414262 -0.76689376 -1.09864526 -0.1307871  -0.63674802\n",
      "  -0.32161549 -0.156286   -0.11719231  0.22978928  1.43584138  0.44903122\n",
      "  -0.09875908  0.77282526  0.38089937]]\n",
      "Accuracy on set aside test set for  std  =  0.921223958333\n",
      "best_lambda =  0.6\n",
      "Coefficients =  [-4.60944128] [[-0.45145759 -0.28466462 -0.06326929  0.68295889  1.21053267  0.91505182\n",
      "   2.83046514  1.43679096  0.24145529  0.35776707 -0.38644407 -0.48143415\n",
      "  -0.69587017  0.37456789  0.64885559  1.53956347  1.38117822  0.07197443\n",
      "   0.37642872  0.63502236  0.5227408   0.38563883  2.00139485  1.50816969\n",
      "  -3.14061245 -0.66616129 -4.90648744 -0.0325956  -1.28886415 -0.1574577\n",
      "  -0.6390073  -0.3023048  -1.00989869 -0.42569126 -1.08722214  1.28435133\n",
      "  -0.90558566 -0.35286054 -1.12971576 -0.62591321 -1.40337384 -2.44124209\n",
      "  -1.55654167 -1.94777881 -1.13114751 -2.79991602 -0.75122173 -2.11603146\n",
      "  -1.68511663 -0.66774001 -0.69125907  2.06912393  4.21977422  0.76308597\n",
      "   0.70345787  0.1700838   0.43018827]]\n",
      "Accuracy on set aside test set for  logt  =  0.943359375\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-1.82566817] [[ -1.78313887e-01  -1.60085507e-01  -3.73001110e-01   2.36358803e-01\n",
      "    9.46367589e-01   1.59613651e-01   2.03690641e+00   7.62617293e-01\n",
      "    1.81159712e-01   3.12388353e-01  -2.60352275e-01  -4.14115142e-01\n",
      "   -8.66097179e-01   2.36335389e-01   4.75358416e-01   1.43030139e+00\n",
      "    8.23118667e-01  -6.18540129e-02   2.39595774e-01   4.50237962e-01\n",
      "    7.24354333e-01   1.06352180e+00   8.70212070e-01   1.30340906e+00\n",
      "   -2.20348245e+00  -4.57176449e-01  -3.39242058e+00   5.45347538e-01\n",
      "   -5.60588208e-01  -1.85244388e-01  -8.05548612e-01  -4.84223732e-01\n",
      "   -6.36751902e-01  -8.68074821e-02  -6.31860076e-01   3.04485693e-01\n",
      "   -1.03756760e+00   4.18380737e-01  -7.08628404e-01  -2.18361508e-01\n",
      "   -1.07385026e+00  -1.74862153e+00  -6.95533233e-01  -1.43004581e+00\n",
      "   -7.40200633e-01  -2.11078936e+00  -9.46977028e-02  -1.24285032e+00\n",
      "   -2.91376073e-01   1.90460650e-01  -1.65731168e-01   1.19345678e+00\n",
      "    1.42337675e+00   6.04361398e-02   7.86190528e-04   7.86190528e-04\n",
      "    7.86190528e-04]]\n",
      "Accuracy on set aside test set for  bin  =  0.928385416667\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-11.76634933] [[ -5.30556487e-02  -2.02986608e-01   1.08790180e-01   2.86589799e+00\n",
      "    2.68931612e-01   2.58579580e-01   9.00118462e-01   2.98480528e-01\n",
      "    2.26902600e-01   6.96761481e-02  -6.90529748e-02  -1.54184051e-01\n",
      "   -3.28045699e-02   1.60328733e-02   1.62792050e-01   7.99337142e-01\n",
      "    5.34933081e-01   3.53431047e-02   2.68969167e-01   3.32140803e-01\n",
      "    2.54975766e-01   3.39371272e-01   6.95175982e-01   1.75181369e-01\n",
      "   -3.22270196e+00  -3.20778290e-01  -4.37258614e+01  -6.03569188e-02\n",
      "   -1.44141311e+00  -1.29487806e-02   1.78095257e-01   5.67112950e-01\n",
      "   -3.28871868e-01  -1.03599908e-01  -7.29961147e-01   4.34452499e-01\n",
      "    5.82457804e-02  -1.55483613e-01  -4.52348329e-01  -4.05583391e-02\n",
      "   -5.27160594e+00  -1.85034072e+00  -5.18194455e-01  -1.01237611e+00\n",
      "   -9.15909311e-01  -1.76673575e+00  -1.69885293e-01  -1.20311823e+00\n",
      "   -3.52308870e-01  -1.35738277e-01  -5.44427003e-02   1.98273061e-01\n",
      "    1.71003097e+00   1.09454193e+00   4.47762714e-02   2.57499547e+00\n",
      "    3.16313377e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.92578125\n",
      "best_lambda =  5.1\n",
      "Coefficients =  [-3.91308812] [[ 0.          0.          0.          0.          1.00929218  0.26464953\n",
      "   2.5824928   1.16523601  0.          0.11140787  0.         -0.41670797\n",
      "   0.          0.          0.          1.42827275  0.9217024   0.\n",
      "   0.27726305  0.          0.55788208  0.04658662  1.49829303  1.1236299\n",
      "  -3.00434332 -0.15634475 -3.67611161  0.          0.          0.          0.\n",
      "   0.         -0.45086436  0.          0.          0.         -0.72497878\n",
      "   0.         -0.34600898  0.          0.         -1.33607199  0.\n",
      "  -0.59359677 -0.73300941 -2.33419328  0.         -0.08241912 -0.02893678\n",
      "   0.          0.          1.86738147  3.65772073  0.          0.34183915\n",
      "   0.34165323  0.25311971]]\n",
      "Accuracy on set aside test set for  logt  =  0.932942708333\n",
      "best_lambda =  3.6\n",
      "Coefficients =  [-0.69589389] [[ 0.          0.         -0.19376579  0.          0.86590323  0.\n",
      "   2.02973593  0.63348234  0.02645191  0.21232661  0.         -0.42146953\n",
      "  -0.68111317  0.          0.          1.31582672  0.76609645  0.\n",
      "   0.10804561  0.12267655  0.63485509  0.73051583  0.62136343  1.18370401\n",
      "  -2.42484481 -0.12474117 -3.7313869   0.          0.          0.          0.\n",
      "   0.         -0.28817004  0.         -0.21920734  0.         -1.01556167\n",
      "   0.         -0.40509156  0.         -0.11529703 -1.69453935 -0.03908735\n",
      "  -1.11008437 -0.68766755 -2.2196063   0.         -1.02540882 -0.12504441\n",
      "   0.07430327  0.          1.15069735  1.5003372   0.         -0.73573648\n",
      "  -0.13225991 -0.10289633]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
